# GitCook-Agent 项目评估与面试问答清单（专家视角）

> 本文档从**资深 Agent 开发/系统设计面试官**的视角出发，  
> 系统性整理了：
>
> 1. 当前项目**需要补齐的关键工程能力**
> 2. 面试中**可用于判断真实工程实力的问题清单**
>
> 可直接用于：
> - 项目自查 / 技术复盘  
> - 面试准备（作为被面试者）  
> - 技术面试（作为面试官）

---

## 一、项目需要补齐的关键能力（工程闭环视角）

整体评价：  
> **设计方向正确，系统结构合格，但尚未形成“可长期运行的工程闭环”。**

以下能力若缺失，项目在真实用户、真实数据规模下容易失控。

---

### 1. 可观测性（Observability）不足

当前问题：
- 无法清晰回答：**“这次回答为什么是这样产生的？”**
- 无法快速定位错误来源（切分 / 检索 / 锁定 / 生成 / 联网）

需要补齐：
- 每次请求的 **完整决策轨迹日志**
  - Intent 结果
  - RRF 排名
  - Parent 聚合分数
  - HITL 是否触发 & 原因
  - 是否锁定 / 解锁
  - Grader 判断
  - 是否联网
- 可回放的会话日志（Replay）
- Query → Chunk → Parent → Answer 的可追溯链路

---

### 2. Grader 可靠性与成本控制未量化

风险点：
- Grader 误判 Relevant → 胡答
- Grader 误判 Irrelevant → 频繁联网，成本暴涨

需要补齐：
- Grader 的离线准确率评估
- 不同置信度阈值下：
  - 联网比例
  - 用户满意度
  - 平均成本
- fallback 触发的统计与回溯分析

---

### 3. 安全与一致性策略不完整

主要风险：
- Web Search Prompt Injection
- 锁定版本被“其他版本步骤”污染
- 不同来源信息互相覆盖

需要补齐：
- 联网内容的指令剥离与白名单策略
- 明确区分：
  - 锁定菜谱内容
  - 通用原理补充
- 明示“不一致风险”的提示机制

---

### 4. 评估体系仍偏“模块级”

已有：
- Hit Rate@3
- 意图分类准确率
- Faithfulness 指标

缺失：
- 端到端任务成功率（用户是否真的做成了）
- HITL 是否必要 / 是否减少错误锁定
- 锁定正确率（Lock Accuracy）
- 用户交互成本（需要点几次才能开始做菜）

---

### 5. 数据更新与索引一致性策略不清晰

工程风险：
- HowToCook 更新后 parent_id 变化
- 旧会话锁定失效
- 缓存与索引不一致

需要补齐：
- 稳定 parent_id 生成策略
- 增量索引与回滚机制
- 会话跨版本的降级/提示策略

---

## 二、面试官视角：核心面试问题清单

> 以下问题用于判断：  
> **候选人是否真正做过 Agent / RAG 系统，而不只是写过设计文档。**

---

### 1. 目标与系统边界

1. 你如何定义这个 Agent 的“成功”？有哪些可量化指标？
2. 推荐 / 教学 / 问答 三类意图的边界如何区分？
3. 遇到复合请求（推荐 + 教学）你如何拆解或处理？

---

### 2. 分块与索引设计

4. 结构化分块在真实脏数据中如何兜底？
5. 上下文增强为什么一定有用？你如何验证它提升了效果？
6. parent_id 如何保证跨版本稳定？
7. 子块粒度如何选择？你如何做取舍？

---

### 3. 召回与排序策略

8. 为什么选择 RRF？有没有对比其他融合策略？
9. BM25 错召回时，你如何避免被“关键词误导”？
10. Parent 聚合为什么用 coverage / sum score？是否考虑过学习排序？
11. query 很短时如何防止热门菜谱霸榜？

---

### 4. HITL 与 Lazy-Locking

12. “分数相近”的阈值如何确定？如何避免频繁打断用户？
13. HITL 卡片字段如何设计才能真正帮用户决策？
14. 锁定后局部检索是否可能降低召回质量？
15. 用户表达“换一个版本”时，你如何判断是解锁还是二次 HITL？

---

### 5. Grader 与 Web Fallback

16. Grader 的输入输出结构是什么？误判代价如何控制？
17. 如何避免“检索质量差但 Grader 判 Relevant”的情况？
18. Web Search 如何防 Prompt Injection？
19. 联网内容如何对齐 HowToCook 的结构与版本？
20. 如何限制联网比例与整体成本？

---

### 6. 评估与可观测性（资深必问）

21. 你有哪些离线评估集？如何覆盖不同 Query 类型？
22. 你如何衡量 HITL 与 Lazy-Locking 是否真的有价值？
23. 系统日志是否支持完整会话回放？
24. 出现错误步骤时，你如何快速定位根因？
25. 你是否做过任何安全或风险约束？

---

### 7. 工程化与扩展性

26. 数据更新频率？增量索引如何保证一致性？
27. 锁定状态如何存储？过期与清理策略是什么？
28. 如果替换 Embedding 模型或向量库，哪些模块不应受影响？

---

## 三、面试官判断标准（内部参考）

- **只能讲架构，不讲失败案例 → 高风险**
- **能描述完整一次 query 的决策路径 → 合格**
- **能量化 HITL / Lock / Fallback 的收益 → 高级**
- **能讲清楚“哪里可能错 & 怎么兜底” → 资深**

---

## 四、总结

> 这是一个**设计水平已经合格**的 Agent 项目，  
> 但要达到 **“可长期运行、可维护、可扩展”** 的工程级别，  
> 必须补齐：
>
> - 可观测性  
> - 评估闭环  
> - 成本与安全控制  
> - 数据更新策略

**补齐这些，它就是一个非常有说服力的“资深 Agent 项目”。**
